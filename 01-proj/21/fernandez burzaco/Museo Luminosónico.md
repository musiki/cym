---
type: project
author: Agustín Fernández Burzaco
tags: proyectual
publish: 2021
---
## Síntesis

Museo Luminosónico es una aplicación web que recrea un espacio de museo virtual. En él, el espectador observa y escucha diferentes objetos luminosónicos que puede modificar a través de la operación sobre diferentes comandos que afectan al sonido y a la imagen en simultáneo.

## Objetivos:

-   Crear un museo virtual interactivo.
    
-   Crear un objeto multimedial luminosónico en el que sonido e imagen se hallen relacionados como consecuencia de la sincronización de los cambios que afectan a cada medio (visual y sonoro, imagen y sonido).
    
-   Generar un fenómeno de síncresis entre imagen y sonido.
    
-   Generar sensación de espacialidad y profundidad dentro de la pantalla desde la interacción entre audio e imagen.
    
-   Crear parámetros multimediales a través de la asociación entre parámetros de la imagen y parámetros del sonido.
    
    
    ## Justificación/ Memoria conceptual:
    
    Como consecuencia de la reflexión sobre las posibilidades de relación entre imagen y sonido, la creación del Museo Luminosónico resulta de la búsqueda de generar un fenómeno de síncresis entre imagen y sonido, y de crear un objeto multimedial luminosónico en el que sonido e imagen se hallen relacionados.
    
    En base al escrito de Adam Basanta Shades of Synchresis: A Proposed Framework for the Classification of Audiovisual Relations in Sound-and-Light Media Installations (2012), un objeto luminosónico es comprendido como un objeto audiovisual en el que ambos medios (visual y sonoro) son percibidos como un material integrado y compuesto. Sonido y luz están
    

siempre relacionados el uno al otro, y mutuamente constituyen el entendimiento percepual del objeto luminosónico. En palabras del propio autor:

“A luminosonic object is in this regard an audiovisual object in which – by virtue of the localized production of sound and light – the two media are perceived as integrated, composite material. That is, sound and light are always in relation to one another, mutually constituting our perceptual understanding of the luminosonic object.”

Basanta, Adam. Shades of Synchresis: A Proposed Framework for the Classification of Audiovisual Relations in Sound-and-Light Media Installations, 2012.

Acerca de las posibles relaciones entre sonido e imagen, Basanta reflexiona sobre las ideas de Michel Chion en su escrito Audio-vision: Sound on Screen (1994), quien se enfoca en el fenómeno de “valor agregado” en el medio cinematográfico. Chion define al mismo como el enriquecimiento del sonido por la imagen y de la imagen por el sonido. A su vez, afirma que dicho “valor agregado” debe manifestarse en una animación temporal de la imagen a través del sonido o viceversa. Chion identifica, también, una subcategoría de “valor agregado” a la que él denomina síncresis (que consiste en una combinación entre sincronía y síntesis), para describir la asociación y relación entre el fenómeno auditivo y el fenómeno visual. Según Chion, la síncresis puede ocurrir independientemente de cualquier lógica racional, lo que lleva a la aglomeración perceptiva de combinaciones dispares de imagen y sonido. Sin embargo, según el autor, la fuerza de la experiencia sincrética puede depender de funciones de significado, determinaciones contextuales, leyes gestálticas y ritmo.

Por otra parte, Basanta menciona las categorías establecidas por John Coulter en Electroacoustic Music with Moving Images: the art of media pairing(2010) para definir posibles relaciónes entre imagen y sonido. Una de ellas es la relación isomórfica: las relaciones isomórficas son definidas a través de la presencia de características formales compartidas y manifiestas entre imagen y sonido, que a su vez se comportan de manera sincrónica en el ámbito temporal. Los estímulos visuales y sonoros de los objetos relacionados isomórficamente son percibidos a través de un único esquema mental que deviene en la percepción de un objeto trans-modal o multimedial.

En relación a ello, el desarrollo del Museo Luminosónico busca generar relaciones isomórficas entre imagen y sonido, con el objetivo de crear un fenómeno de síncresis entre ambos medios.

Por otra parte, el interés del proyecto radica también en generar una obra que ofrezca una experiencia interactiva al usuario, y que, a su vez, esté relacionada al rol del espectador en el arte de instalación.

|   |
|---|
|Según Boris Groys, en La Topología del Arte Contemporáneo (2009), en una instalación|
|artística el espectador se coloca en una situación de elección y queda confrontado por la necesidad de desarrollar una estrategia individual de contemplación y experiencia con la misma.<br><br>Según Julie Reiss, el espectador es comprendido como un sujeto incorporado a la obra, activo y participativo; y, a su vez, está considerado, en cierta manera, como parte integral de la conclusión de la obra” (es decir, la obra se “completa” con la presencia del espectador).|


|Por último, según Claire Bishop en Installation Art: A critical History (2005), el espectador de una instalación artística es un espectador activo, ya que las instalaciones niegan al espectador el sitio ideal desde el cual contemplar la obra: se caracterizan por no proporcionar una posición|
|privilegiada desde donde observar la obra o el espacio, sino que permiten un número indeterminado de puntos de vista. Y, por ello, el desplazamiento del espectador dentro de la obra es un hecho inherente a las relaciones internas de la obra. Según la autora, las instalaciones instituyen al sujeto como un componente fundamental de la misma.<br><br>En relación a lo anterior, el desarrollo de la aplicación estará dirigido a la generación de diferentes posibilidades de interacción entre el usuario y la obra, de manera tal que éste sea un usuario activo y participativo, y que tenga la posibilidad de elegir y tomar decisiones al respecto de la misma.<br>
## Estado del arte

Existen numerosos museos que ofrecen el servicio de visita virtual. A su vez, también existen museos virtuales como lo es Emaze, de Melissa Ramos y Paola Bravo.|
|Por otra parte, la búsqueda de relacionar imagen y sonido tiene tradición en la historia del cine y en obras de diferentes artistas como Oskar Fischinger.<br><br>Existen, a su vez, aplicaciones web que manifiestan y evidencian relaciones entre imagen y sonido, como lo son Patatap, de Jono Brandel, PixelSynth de Olivia Jack y el doodle de Google en homenaje a Oskar Fischinger.|

## Desarrollo:

El Museo Luminosónico es una aplicación web que consiste en recrear de manera virtual un espacio de sala de museo con imágenes (pinturas o fotografías) sonorizadas en exposición. En él, cada imagen se halla correspondida y relacionada a una música específica que suena en simultáneo a la observación de la misma. Es decir, cada imagen está asociada a una música o audio.

A su vez, el usuario tiene la posibilidad de modular imagen y sonido en simultáneo a través de una serie de comandos especificados en la pantalla de la aplicación. Las modulaciones posibles que pueden realizarse sobre imagen y sonido son comprendidas y diseñadas en función a la generación de un fenómeno de síncresis entre imagen y sonido. El objetivo es que ambos medios (imagen y sonido) sean comprendidos como un único objeto multimedial que puede ser modulado a través de la realización de operaciones sobre diferentes parámetros multimediales (parámetros sono-visuales) que lo definen y componen. Cada parámetro multimedial estará asociado a un comando del mouse o teclado, o ambos en combinación.

Dichos parámetros sono- visuales modulables por el usuario son:

1. a)  Difuminación sono-visual: resulta de la asociación entre la difuminación de la imagen y la reverberación del sonido.
    
2. b)  Luminosidad sono- visual: resulta de la asociación entre la luminosidad de la imagen y la frecuencia de filtro que afecta al sonido.
    
3. c)  Distorsión sono- visual: resulta de la asociación entre la pixelación de la imagen y la distorsión del sonido
    

4. d)  Proximidad sono- visual: resulta de la asociación entre la proximidad virtual de la imagen (con respecto al usuario) y la intensidad del sonido.
    
5. e)  Zoom sono- visual: resulta de la asociación entre el nivel de zoom efectuado sobre la imagen y el nivel de stretching o estiramiento del archivo de audio.
    

Cada uno de los parámetros mencionados es resultado de la asociación de parámetros de la imagen a parámetros del sonido, y, a su vez, cada uno de ellos es comprendido como un único parámetro multimedial.

La selección de imágenes y la composición o recopilación de las músicas vinculadas a cada una de ellas es realizada de antemano como instancia previa a la programación de la aplicación.

Otra opción es utilizar imágenes y animaciones de la aplicación web Hydra, de Olivia Jack como material visual en la obra.

### Principio de funcionamiento:

En la aplicación, el usuario selecciona, de una lista de imágenes sonorizadas disponibles, la imagen sobre la que desea operar y, tras la selección de la misma, ésta se visualiza dentro del marco de una pintura insertada en el espacio de museo virtual. A su vez, al seleccionar la imagen, se relaciona el archivo de audio correspondiente a la misma a un botón de start/ stop, a través del cual se reproduce el audio.

Una vez seleccionada la imagen, el usuario inicia la reproducción del audio y, a continuación, tiene la posibilidad de intervenir las cualidades de la imagen y del sonido a través del uso de diferentes comandos o controles que permiten cambiar los valores de las diferentes variables multimediales que afectan al sonido y a la imagen en simultáneo y de manera sincronizada. Tanto el sonido como la imagen en exposición y la imagen de sala de museo virtual son afectadas por los distintos tipos de modulación.

Cada uno de los comandos realiza una modificación o modulación en el sonido y en la imagen en simultáneo.

Los comandos que pueden ser utilizados por el usuario son:

1. Ctrl+ rueda de desplazamiento: Está asociado a la difuminación sono-visual. Con dicho comando se modifica el nivel de reverberación del audio y de difuminación de la imagen de manera directamente proporcional. Es decir, a mayor nivel de difuminación, el sonido tiene más reverberación y viceversa.

2. Shift+ rueda de desplazamiento: está asociado al nivel de luminosidad sono-visual. Con él se modifica el nivel de brillo/ luminosidad de la imagen y, a su vez, la frecuencia de un filtro que afecta al audio en simultáneo. A menor luminosidad (y mayor opacidad), la frecuencia del filtro es menor, y a mayor luminosidad la frecuencia del filtro es mayor. Otra opción posible es relacionar la frecuencia del filtro al nivel de saturación de los colores de la imagen.

3. Alt+ rueda de desplazamiento: está asociado al nivel de distorsión sono-visual. Con él se puede modificar el nivel de pixelación de la imagen en simultáneo al nivel de distorsión del sonido. Ambas variables están relacionadas de manera directamente proporcional. A mayor pixelación de la imagen, hay mayor distorsión en el sonido, y viceversa.
    
4. Rueda de desplazamiento: está asociada a la proximidad sono- visual y al zoom sono- visual. Con ella se modifica el tamaño de la imagen, con respecto al fondo, en simultáneo a la intensidad del sonido. Cuánto más pequeña es la imagen, menor intensidad tiene el audio, y cuánto mayor tamaño tiene la imagen, mayor es la intensidad del audio. La idea es generar un sentido de espacialidad a través de la relación entre intensidad sonora y tamaño de imagen, con el objetivo de relacionar el tamaño de la imagen a la sensación o percepción de cercanía o lejanía de la misma. El máximo de intensidad sonora se alcanza cuando el tamaño de la imagen coincide con el tamaño de la pantalla.
    
    A su vez, si el tamaño de la imagen es igual al tamaño de la pantalla, se habilita la posibilidad de una segunda operación que consiste en seguir ampliando su tamaño a dimensiones mayores a las de la pantalla misma. En ese caso, el tamaño de la imagen, interpretado como la realización de zoom sobre la misma, está relacionado a la velocidad de reproducción del audio. Cuanto mayor es el tamaño de la imagen en relación al tamaño de la pantalla, menor es la velocidad de reproducción del audio (y, por ello, la duración del archivo de audio es mayor). El objetivo es intentar relacionar el cambio de tamaño de imagen, interpretado como la realización de zoom sobre la misma, al nivel de estiramiento o stretching del archivo de audio, con el objetivo de recrear, a su vez, una posible operación de zoom sonoro que se halle sincronizado al zoom por el que se ve afectada la imagen.
    

### Rol del usuario:

El usuario interactúa con la obra de la siguiente manera:

1. Tiene la posibilidad de elegir, de una lista de imágenes, la imagen sonorizada que quiere intervenir.
    
2. Opera libremente sobre los comandos de modulación sono- visual presentes en la interfaz.
    
3. A partir de ello, puede diseñar un estado específico del objeto luminosónico.
    

## Cronograma/ lista de pasos:

1. Seleccionar las imágenes a utilizar.

2. Elegir las músicas que se asignarán a cada imagen, o componerlas. Exportar como samples en formato wav o mp3.

3. Diseñar el espacio virtual tomando una imagen como fondo.
    
4. Crear botón de start/stop relacionado al archivo de audio.
    
5. Asignar la rueda del mouse como controlador de cercanía/ lejanía entre la imagen y el usuario.
    
6. Relacionar el control de la rueda del mouse también a la intesidad (volumen) de la música.
    
7. Escribir/aprender el código correspondiente a los efectos musicales: reverberación, filtro, distorsión y stretching.
    
8. Escribir/aprender el código correspondiente a los efectos visuales: difuminador, modulador de luminosidad o saturación, pixelador y zoom.
    
9. Asociar los comandos de cada modulador a los parámetros visuales y sonoros correspondientes.
    
10. Averiguar acerca de cómo afectar sólo a la imagen que se situará en el centro de la sala de museo virtual y no a toda la pantalla a la hora de realizar operaciones sobre la imagen. Asignar esa área como área de operación a los moduladores visuales.
    
11. Aprender el código correspondiente a un selector de “modo”. Cada modo se corresponderá a una imagen y a una música (sample).
    
12. Aprender el código para dividir la pantalla en tres partes: un marco, donde se situarán las indicaciones para utilizar los comandos y el botón de Start/stop, un fondo, donde se estará la sala de museo virtual, y un centro, dónde se verá la imagen seleccionada por el usuario.
    

## Diseño de interfaz:

Se eligió como fondo de pantalla una imagen de una sala de museo en cuyas paredes se situán las imágenes a elegir por el usuario. A partir de ello, se busca realizar un posible museo virtual de objetos sonoro-visuales. A su vez, las imágenes pre- seleccionadas pueden ser pinturas o fotografías pertenecientes a la historia del arte visual. En ese caso, las músicas asignadas a cada imagen pueden ser músicas relacionables estilística o históricamente.

Ejemplo no 1:

Ejemplo no2:

Ejemplo no 3:

Ejemplo no 4:

Materiales

Computadora con acceso a internet y servidor para el funcionamiento de la web. Mouse, teclado, monitor y parlantes o auriculares.  
Acceso a estudio de grabación para la grabación de la música.  
Librería de imágenes.

## Presupuesto:

-   Honorarios del compositor musical: $30.000 ARS.
    
-   Honorarios del programador de la aplicación web: $30.000 ARS.
    
-   Honorarios del diseñador de imágenes o artista visual: $30.000 ARS.
    
    TOTAL: $90.000 ARS Referencias:
    

-   Patatap, de Jono Brandel: https://patatap.com
    
-   Doodle de Google en homenaje a Oskar https://www.google.com/logos/doodles/2017/fischinger/fischinger17.9.html?hl=es&d oodle=undefined
    
-   PixelSynth, de Olivia Jack: https://ojack.xyz/articles/pixelsynth/index.html
    
-   Emaze, museo virtual: https://www.emaze.com/@ALIOQCOO
    
    
## Bibliografía:
    

-   Basanta, Adam. Shades of Synchresis: A Proposed Framework for the Classification of Audiovisual Relations in Sound-and-Light Media Installations, 2012.
    
-   Bishop, Claire. Installation Art: A critical History (2005)
    
-   CHION, Michel. Audio-vision: Sound on Screen. Trans. Claudia Gorbman. New York:
    
    Columbia University Press, 1994. Print.
    
-   Groys, Boris. La Topología del Arte Contemporáneo, 2009.
    
Fischinger: